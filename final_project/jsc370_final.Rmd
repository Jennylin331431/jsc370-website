---
title: "What Makes You Happier?"
date: "2023-04-28"
output:
  pdf_document: 
    toc: true 
  html_document:
    df_print: paged
header-includes: 
 \usepackage{float}
 \floatplacement{figure}{H}
---



```{r setup, include=FALSE, echo = FALSE, warning=FALSE,message = FALSE }
knitr::opts_chunk$set(echo = FALSE, results='hide', warning=FALSE, message = FALSE)
```


\newpage 


# Introduction 


Happiness is a viral topic in the modern world, as it is ultimately what everyone longs for. However, according to the World Health Organization, 1 in 8 people suffer from mental disorders, and there has been a 25% increase in depression after COVID-19. With this, I am prompted to know more about how happiness has progressed overtime and the factors that influence it. For instance, in the academic researcher, Satoshi Kanazawa’s paper, “Sunshine on my shoulders makes me happy... especially if I’m less intelligent: how sunlight and intelligence affect happiness in modern society”, he discovers that darkness induces fear and anxiety while exposure to sunlight increases happiness. Not only do I want to explore the effect of sunshine hours, I am also interested in other factors, such as economic status and freedom in a country.


Perhaps, with this report, I hope to provide insights to government policies or personal actions that can help improve the well-being of individuals. Therefore, combining these motivations, I hope to look at happiness from three different aspects, physiological needs (economic status), regional factors (sunshine), and emotional needs (freedom, love). My question of interest is "Do people get happier overtime? Does economic status, freedom to make life choices, and sunshine hours affect people's happiness?".


My first data set is retrieved from a renown source, [World Happiness Report](https://worldhappiness.report/), which is a report written by members of the United Nations Sustainable Development Solutions Network. It makes use of the "Gallup World Poll", a global survey data that consists of over 100 questions including regional specific questions. The report provides insights in how people evaluate their own lives by country. The data set I will be using has records starting from 2005 to 2021, where the happiness score - the national average response to the question of measuring oneself on life ladders - is recorded for more than 150 countries worldwide. Other variables I will be using from the data set are log GDP per capita obtained from World Development Indicators, and the freedom to make life choices and perceptions of corruption, results obtained from Gallup World Poll.


The second data set is retrieved from [Wikipedia](https://en.wikipedia.org/wiki/List_of_cities_by_sunshine_duration), which contains a list of sunshine hours for 391 cities, including the yearly and monthly duration. Records of this data set are compiled from numerous sources.

The third data set I utilized is a world cities data retrieved from [SimpleMaps](https://simplemaps.com/data/world-cities), which have been compiling datasets for prominent international organizations for over 11 years. This data set contains information, such as the population and geographical information (latitude and longitude) for over 40k cities worldwide. This data set is compiled from numerous reliable sources, which includes NASA, National Geospatial-Intelligence Agency, U.S. Census Bureau, and U.S. Geological Survey. This data set will specifically be used with the sunshine data set to find which cities are a better representation for the country in terms of sunshine hours.


```{r, message=FALSE}
#libraries
library(rvest)
library(tidyverse)
library(dplyr)
library(ggpubr)
library(ggplot2)
library(magrittr)
library(kableExtra)
library(scales)
library(xgboost)
library(gbm)
library(leaflet)
library(caret) 
library(gamair)
library(mgcv)
library(randomForest)
library(leaflegend)
library(ggpubr)
```




```{r}
#scrape sunshine data

# Specify the url for desired website to be scraped
url <- 'https://en.wikipedia.org/wiki/List_of_cities_by_sunshine_duration'

# Read the HTML code from the website
webpage <- read_html(url)

# Use CSS selectors to scrape the table
table <- html_nodes(webpage,'table.wikitable')

# Converting the table to a data frame
table <- html_table(table, header = TRUE)

sunshine_data <- table %>%
  bind_rows() %>%
  as_tibble()
```

```{r}
#load happiness score data
happiness_data<- read.csv('../data/DataPanelWHR2021C2.csv')
```


```{r}
#load population data
pop_data <- read.csv('../data/worldcities.csv')
```


\newpage 

# Methods


## Data Collection 
The happiness data set is downloaded from the [World Happiness Report](https://worldhappiness.report/ed/2022/#appendices-and-data) website. The process is as easy as a simple download for “Data for Table 2.1”, which is downloaded as an excel file. I later converted to a csv myself. 


The second data set uses the "rvest" package from R to perform web scraping from Wikipedia; it uses the URL to read HTML code and CSS selectors to subsequently scrape the table.

The cities census data set is retrieved from [SimpleMaps](https://simplemaps.com/data/world-cities), which is available for download in csv or excel format. 


## Data Wrangling & Cleaning

**Data 1: Sunshine Data set**

This is a sample table of the data set. 

```{r, results = 'show'}
#display raw sunshine data
head(sunshine_data,5) %>% 
  knitr::kable(caption = "Raw Data from Wikipedia Sunshine Hours") %>% 
  kable_styling(latex_options=c("scale_down","HOLD_position"))
```

```{r}
#check for null values 
sum(is.na(sunshine_data))

#count number countries
n_distinct(sunshine_data$Country)
```
This data set contains the sunshine hours for 391 cities from 141 countries. I checked for null values in the sunshine data set and discovered that the data set is free of null values. I then converted the yearly sunshine duration from characters to numeric data. I also checked for abnormal values. For instance, I checked the locations of maximum and minimum yearly sunshine in the data set, which appear in Yuma, United States, and Tórshavn, Faroe Islands, respectively. I validated that both of these observations are accurate. To prepare for merging, since sunshine hours are reported by cities, while our happiness data set is reported in countries, I created a new data frame that records mean yearly sunshine, maximum yearly sunshine, minimum yearly sunshine for each country. 


```{r}
#convert year column to numeric 
sunshine_data$Year = gsub(",", "", sunshine_data$Year)
sunshine_data$Year = as.numeric((sunshine_data$Year))
```

```{r}
#check which countries have max and min sunshine hours

sunshine_data[which.max(sunshine_data$Year),]

sunshine_data[which.min(sunshine_data$Year),]

```

```{r}
#create average, min, max of sunshine hours in each country
sunshine_summary <- sunshine_data %>% group_by(Country) %>%
summarise(average_sunshine = mean(Year, na.rm = TRUE),
              max_sunshine = max(Year, na.rm = TRUE),
              min_sunshine = min(Year, na.rm = TRUE), n = n())
```


```{r}
# summary of raw happiness data
summary(happiness_data)
```
**Data 2: Happiness Data**

Below is a sample table of the data set. 

```{r, results = 'show'}
#display sample of happiness data
head(happiness_data,5) %>% 
  knitr::kable(caption = "Raw Data from World Happiness Report")  %>% 
  kable_styling(latex_options=c("scale_down","HOLD_position"))
```
```{r}
#count null values
sum(is.na(happiness_data))

#remove null values

#original number of observations 
nrow(happiness_data)

#remove null values

happiness_data <- happiness_data %>% drop_na(Log.GDP.per.capita, Freedom.to.make.life.choices)

# number of observations after removal
nrow(happiness_data)
```



```{r}
#Change observation country name to match in both data sets 
sunshine_data <- sunshine_data  %>%
  mutate(Country.name = case_when(Country == 'Democratic Republic of the Congo' & 
                                    City == "Kinshasa" ~ "Congo (Kinshasa)", 
                                  Country == 'Congo' 
                                  & City == "Brazzaville" ~ "Congo (Brazzaville)", 
                                  Country == "China" & City == 'Hong Kong' ~ "Hong Kong S.A.R. of China",
                                  Country == "United ArabEmirates" ~ "United Arab Emirates",
                                  Country == 'Taiwan' ~ "Taiwan Province of China",               
                         TRUE ~ Country))

#create average, min, max of sunshine hours in each country
sunshine_summary <- sunshine_data %>% group_by(Country.name) %>%
summarise(average_sunshine = mean(Year, na.rm = TRUE),
              max_sunshine = max(Year, na.rm = TRUE),
              min_sunshine = min(Year, na.rm = TRUE), n = n())

sunshine_summary
```

There are 36 NA values in log GDP per capita and 32 NA values in the "Freedom.to.make.life.choices" variable, which I removed. 68 observations were removed in total and 1881 observations remaining. The happiness dataset is very well compiled; the data set is free from abnormal values. As an extra validation, I checked whether freedom scores are between 0 and 1 and whether the GDP is between an acceptable range. I also checked whether there were distinct or duplicated happiness scores for the same country in the same year.  

To prepare for merging the happiness data set and sunshine data set, I modified a few country names within the sunshine data set to match that of the happiness data. This is because I recognized that some countries are named differently. For instance, 'Taiwan' in the sunshine data is named "Taiwan Province of China" in the happiness data. A total of 5 names were changed.

```{r}
# inspect population data 
summary(pop_data)
```

```{r}
#check na values in data 
sum(is.na(pop_data$population))

# number of observations 
nrow(pop_data)

#below is to check whether the NA population entries affect our merging in the future
country_list <- happiness_data$Country.name
sunshine_country_list <- sunshine_data$Country
sunshine_city_list <- sunshine_data$City


not_na_pop_data <- pop_data %>% filter(!is.na(pop_data$population)) 
not_na_c <- unique(not_na_pop_data$country)

na_pop_data <- pop_data %>% filter(!country %in% country_list & is.na(pop_data$population) & !country %in% not_na_c  & country %in% sunshine_country_list & city %in% sunshine_city_list) 

na_pop_data
```



**Data 3: World Cities Data**

Below is a sample table of the data set. 

```{r, results = 'show'}
#sample dataset of population city data 
head(pop_data,5) %>% 
  knitr::kable(caption = "Raw Data from World Cities Dataset")  %>% 
  kable_styling(latex_options=c("scale_down","HOLD_position"))
```


There are a total of 44691 observations in this data set, and 307 of which have empty entries for the population column. However, after a thorough check, none of these empty population entries will affect our merging with the sunshine hours data, as these cities are either in countries that are not present in the happiness data set, or these cities are in countries that have other cities with non-empty population, which can be used to calculate for maximum population.


## Data Merging/Filtering - Sunshine Hours Data & World Cities Data 


As I have mentioned previously, the sunshine data set only contains sunshine hours for cities specifically; however, the happiness data is only recorded by country. Therefore, we need to obtain the country sunshine hours. There are many ways to do this, such as averaging the sunshine hours over all cities within the country or choose a deciding factor for which cities are a better representation for the country. I chose "population" to be the deciding factor, since in my opinion, higher population means that more people in this country are receiving this amount of sunshine hours.

Prior to merging the sunshine data set with the world cities population data set, one major modification required within the world cities data set are to match the city names. Some of them do not match that of the sunshine data set. Some changes I made include changing "Viljandi" to "Vilsandi" in the sunshine, "Luxembourg" to "Luxembourg City", and "New York" to "New York city" in the world cities data. Other name changes were also required when there were special language characters in city names, such as "Montréal" and "Kolkāta". Moreover, I changed a couple of country names. For example, I imputed the country for "Macau" which was empty previously, and changed "Saint Pierreand Miquelon" in the sunshine data set to be free of typos. One special case is "Tel Aviv" which was recorded as a city in the sunshine but a capital in the world cities data set. Therefore, to calculate the population, I summed up all population in the Tel Aviv first. A total of 30 cities were modified to prepare for merging.


```{r}
#rename cities in world cities data to match in merge 
pop_data <- pop_data  %>%
  mutate(city = case_when(city == "Montréal"~ "Montreal",
                          city == "N’Djamena"~ "N'Djamena",  
                          city == "Djibouti"~ "Djibouti City",     
                         city == "Viljandi"~ "Vilsandi",     
                         city == "Addis Ababa"~ "Addis Abeba",     
                         city == "Reykjavík"~ "Reykjavik",     
                         city == "Kolkāta"~ "Kolkata",     
                         city == "Bandar ‘Abbās"~ "Bandar Abbas",     
                         city == "Luxembourg"~ "Luxembourg City", 
                         city == "Chisinau"~ "Chișinău",     
                         city == "Petropavlovsk-Kamchatskiy"~ "Petropavlovsk-Kamchatsky",     
                         city == "Abhā"~ "Abha",     
                         city == "Zürich"~ "Zurich",
                         city == "Dar es Salaam"~ "Dar-es-Salaam",
                         city == "Sansanné-Mango"~ "Mango",     
                         city == "Gabès"~ "Gabes",     
                         city == "New York"~ "New York City",     
                         city == "Portland" & admin_name == "Oregon" ~ "Portland (OR)",     
                         city == "Ciudad Bolívar"~ "Ciudad Bolivar",    
                         city_ascii == "Da Lat"~ city_ascii,     
                        city_ascii == "Da Nang"~ city_ascii,     
                            city == "Washington"~ "Washington,D.C.",   

                         TRUE ~ city))


#cities with incorrect/debatable country names 
pop_data <- pop_data  %>%
  mutate(country = case_when(
                         city == "Macau"~ "China", 
                         city == "Prague" ~"Czech Republic", 
                         city == "Banjul" ~"Gambia", 
                         country == "Hong Kong" ~ "Hong Kong S.A.R. of China",
                         country == "Saint Pierre and Miquelon" ~ "Saint Pierreand Miquelon",
                          country == "Taiwan" ~ "Taiwan Province of China",
                         TRUE ~ country))

# fix typos in sunshine data country
sunshine_data <-  sunshine_data  %>%
  mutate(Country.name = case_when(
                         Country.name == "Saint Pierreand Miquelon" ~ "Saint Pierre and Miquelon",
                         TRUE ~ Country.name))

# fix typos in sunshine data cities
sunshine_data <-  sunshine_data  %>%
  mutate(City = case_when(
                         City == "OklahomaCity" ~ "Oklahoma City",
                         TRUE ~ City))


```


```{r}
#merge sunshine data and population data
sunshine_by_city <- merge(sunshine_data, pop_data,  by.x = c("Country.name", "City"), by.y = c("country", "city"), all.x = TRUE)
summary(sunshine_by_city)
```

```{r}
#use the summed population for Tel Aviv
sum_pop_by_capital <- pop_data %>% group_by(admin_name) %>%
  mutate(population_by_capital = sum(population)) 
tel_aviv_pop <- sum_pop_by_capital %>% filter(admin_name == "Tel Aviv") %>% pull(population_by_capital)


#impute for Tel Aviv 
sunshine_by_city <- sunshine_by_city %>%
  mutate(population = case_when(City == "Tel Aviv" ~ 2343287, 
                                TRUE ~ population))

```

```{r}
#cities still with no population values after merging
temp<- sunshine_by_city %>% filter(is.na(population)) %>% select(Country.name,City)
temp
```

After merging, I realized that there are still 28 cities that do not have population records. For cities whose country is not present in the happiness data set or cities which are in countries that already have cities with population records, it will not be a problem to obtain the max populated cities.

There were only 2 countries that require imputation for population, "Ivory Coast” and "North Macedonia", which are both not in the world cities data set. Therefore, I chose Abidjan and Skopje as the cities to represent sunshine hours after learning they are the capitals in "Ivory Coast” and "North Macedonia" respectively. Afterwards, I only kept the the highest populated cities as a representation for sunshine hours for all the countries.

To see a visualization of the selection of cities as representation for sunshine hours and the sunshine hours data set in each country geographically, please refer to Interactive Visualizations: [Figure 1](https://jennylin331431.github.io/jsc370-website/final_project_visuals.html#Figure_1). 
/
```{r}
# cities with the maximum population by country
max_pop_cities <- sunshine_by_city %>% group_by(Country.name) %>% filter(population == max(population, na.rm = TRUE)) %>% select(Country.name, City)
max_pop_cities


# number of countries don't have maximum
n_distinct(sunshine_by_city$Country.name) - n_distinct(max_pop_cities$Country.name)


#the countries that are in happiness data but have empty population records 
keep <- sunshine_by_city %>% filter(!Country.name %in% max_pop_cities$Country.name & Country.name %in% happiness_data$Country.name) 
keep

#directly select representational cities for Ivory Coast and North Macedonia
keep <- keep %>% filter(Country.name == "Ivory Coast" & City == "Abidjan" |Country.name == "North Macedonia" & City == "Skopje")  %>% select(Country.name, City)

# the cities that we use as representational sunshine hours 
keep <- rbind(keep, max_pop_cities)
```
```{r}
#sunshine data based on cities with highest population
sunshine_by_pop <- merge(sunshine_data, keep,
      by.x=c("Country.name","City"), 
      by.y=c("Country.name","City"))



sunshine_by_pop <- sunshine_by_pop %>% rename("Avg_sunshine" = "Year")

drop_cols <- c("Ref.", 
"Country")


#remove not needed columns 
sunshine_by_pop <- sunshine_by_pop[,!names(sunshine_by_pop) %in% 
      drop_cols]
```


```{r, results = 'show'}
# sample table of merged data set
head(sunshine_by_pop, 5) %>% 
  knitr::kable(caption = "Country Sunshine Data by Highest Populated cities") %>% 
  kable_styling(latex_options=c("scale_down","HOLD_position"))
```






```{r}

#representational cities
leaflet_marker <-  merge(sunshine_by_pop, pop_data,
      by.x=c("Country.name","City"), 
      by.y=c("country","city"), all.x = TRUE)

#palette
rh_pal <- colorNumeric(
  # c('lightgrey','lightblue','blue'),
  viridisLite::viridis(5, direction = -1),
  domain = sunshine_data$Year
  )


#create sunshine level for colors
leaflet_marker <- leaflet_marker %>% mutate(sunshine_level = case_when((
  Avg_sunshine <= quantile(leaflet_marker$Avg_sunshine, probs =0.25, na.rm = TRUE)) ~ "pink",
  (Avg_sunshine > quantile(leaflet_marker$Avg_sunshine, probs =0.25, na.rm = TRUE) & 
     Avg_sunshine <= quantile(leaflet_marker$Avg_sunshine, probs =0.75, na.rm = TRUE)) ~ "red",
  (
  TRUE ~ "blue")))


# icon for sunshine level marker 
icons <- awesomeIcons(
  icon = 'ios-close',
  iconColor = 'white',
  library = 'ion',
  markerColor = leaflet_marker$sunshine_level
)

# icon set for creating legend in leaflet 
iconSet <- awesomeIconList(
  `Low` = makeAwesomeIcon(icon = 'ios-close',
  iconColor = 'white',
  library = 'ion',
  markerColor = "pink",
  ),
  Medium = makeAwesomeIcon(icon = 'ios-close',
  iconColor = 'white',
  library = 'ion',
  markerColor = "red",
  ),
  High = makeAwesomeIcon(icon = 'ios-close',
  iconColor = 'white',
  library = 'ion',
  markerColor = "blue",
  ))

```

```{r}
# saveRDS(leaflet_marker, file = "leaflet_marker.rds")
# saveRDS(sunshine_by_city, file = "sunshine_by_city.rds")
# saveRDS(sunshine_data, file = "sunshine_data.rds")
```


```{r}
# # leaflet map for sunshine hours in countries
# leaflet() %>%
#   addProviderTiles('OpenStreetMap') |>
#   addCircles(lat = ~lat, lng = ~lng, color = ~rh_pal(Year),
#              label = ~paste0(City, ': ', round(Year,2), ' hrs\n'),
#              opacity = 1, fillOpacity = 0.8, radius = 600, data = sunshine_by_city) |>
#   addAwesomeMarkers(lat = ~lat, lng = ~lng, icon=icons, data = leaflet_marker, label = ~paste0(leaflet_marker$City, ': ', round(leaflet_marker$Avg_sunshine,2), ' hrs\n'))|>
#   addLegend('bottomleft', pal = rh_pal, values = sunshine_by_city$Year,
#             title = "Yearly Sunshine Hours", opacity=1)|>
# 
#   addLegendAwesomeIcon(iconSet = iconSet, title = 'Sunshine Level',
#                        position = 'topleft',
#                        group = 'Awesome Icons')
```



## Data Merging - Happiness Data & Sunshine Data

After merging the data set, I discovered that there are still around 30 countries out of 161 countries which do not have sunshine hours reported. After carefully examining these countries, I recognized that they are less renown countries in the world; therefore, I decided to safely remove them from the merged data set. I also removed the columns that are not my variables of my interest, such as generosity, social support, positive effect ... etc.  I renamed the columns to a more accessible format as well. My final merged data set consists of 1553 observations, and below is a sample table. 
```{r}
sunshine_by_pop <- subset(sunshine_by_pop, select = c(Country.name, City, Avg_sunshine))
sunshine_by_pop
```

```{r}
#merge the dataset
data <- merge(happiness_data, sunshine_by_pop,  by = "Country.name", all.x = TRUE)
summary(data)
```

```{r}

#countries without sunshine hours
length(unique(data[which(is.na(data$Avg_sunshine)),]$Country.name))

#number of countries in the dataset
length(unique(data$Country.name))
```
```{r}
data
```


```{r}
#check for null values again 
#remove countries with null values
data <- data %>% drop_na(Avg_sunshine)
sum(is.na(data))
```

```{r}
drop_cols <- c("Social.support", "Healthy.life.expectancy.at.birth", "Generosity",
"Perceptions.of.corruption",
"Positive.affect",
"Negative.affect", 
"City")

# drop_cols_reg <- c(
# "Positive.affect",
# "Negative.affect", "Ref.", 
# "City")

data_reg <- data

#remove not needed columns 
data <- data[,!names(data) %in% 
      drop_cols]

data <- data %>% rename("Country" = "Country.name", "Year" = "year" , "Happiness" = "Life.Ladder","Log_GDP" =  "Log.GDP.per.capita" , "Freedom" = Freedom.to.make.life.choices)

data


# # rename columns 
# colnames(data) <- c("Country","Year","Happiness", "Log_GDP","Freedom","Avg_sunshine", "Max_sunshine", "Min_sunshine")
```

```{r}
#check whether Country and year only correspond to one observation 
df_dups <- data[c("Country", "Year")]

#should be equal
nrow(data) == nrow(data[!duplicated(df_dups),]) 

```



```{r, results = 'show'}
# sample table of merged data set

sample_data <- data %>% filter(Year == 2018) 
head(sample_data , 5) %>% 
  knitr::kable(caption = "Merged Data from World Happiness Report and Sunshine Hours Data") %>% 
  kable_styling(latex_options=c("HOLD_position"))
```



## Data Exploration

I used various R functions, such as summary() and str(), to explore the variables within my data set. Below is a summary of all the variables in the data set. 

```{r}
#summary of final merged data
summary(data)
```
```{r}
#look at final merged data

str(data)
```




```{r}
#create variable summary table for data set

summary_var <- data.frame(

  #variable names
  Variable_Names = c("Country", "Year", "Happiness", "Log_GDP", "Freedom", "Avg_sunshine", "Max_sunshine", "Min_sunshine" ),
  type = c("chr", "int", "num","num","num","num","num","num"),

  #q1
  q1 = c("",  round(quantile(data$Year, probs =0.25, na.rm = TRUE),3), round(quantile(data$Happiness, probs =0.25, na.rm = TRUE),3),round(quantile(data$Log_GDP, probs =0.25, na.rm = TRUE),3), round(quantile(data$Freedom, probs =0.25, na.rm = TRUE),3), round(quantile(data$Avg_sunshine, probs =0.25, na.rm = TRUE),3), round(quantile(data$Avg_sunshine, probs =0.25, na.rm = TRUE),3), round(quantile(data$Avg_sunshine, probs =0.25, na.rm = TRUE),3)),

  #median
  median =  c("", round(quantile(data$Year, probs =0.5, na.rm = TRUE),3), round(quantile(data$Happiness, probs =0.5, na.rm = TRUE),3),round(quantile(data$Log_GDP, probs =0.5, na.rm = TRUE),3), round(quantile(data$Freedom, probs =0.5, na.rm = TRUE),3), round(quantile(data$Avg_sunshine, probs =0.5, na.rm = TRUE),3), round(quantile(data$Avg_sunshine, probs =0.5, na.rm = TRUE),3), round(quantile(data$Avg_sunshine, probs =0.5, na.rm = TRUE),3)),

  #q3
 q3 =  c("", round(quantile(data$Year, probs =0.75, na.rm = TRUE),3), round(quantile(data$Happiness, probs =0.75, na.rm = TRUE),3),round(quantile(data$Log_GDP, probs =0.75, na.rm = TRUE),3), round(quantile(data$Freedom, probs =0.75, na.rm = TRUE),3), round(quantile(data$Avg_sunshine, probs =0.75, na.rm = TRUE),3), round(quantile(data$Avg_sunshine, probs =0.75, na.rm = TRUE),3), round(quantile(data$Avg_sunshine, probs =0.75, na.rm = TRUE),3)),

 #mean
  mean = c("", round(mean(data$Year, na.rm = TRUE), 0), round(mean(data$Happiness, na.rm = TRUE),3), round(mean(data$Log_GDP, na.rm = TRUE),3), round(mean(data$Freedom, na.rm = TRUE),3), round(mean(data$Avg_sunshine, na.rm = TRUE),3), round(mean(data$Avg_sunshine, na.rm = TRUE),3), round(mean(data$Avg_sunshine, na.rm = TRUE),3)),

 #max
  max = c("", round(max(data$Year, na.rm = TRUE),3), round(max(data$Happiness, na.rm = TRUE),3), round(max(data$Log_GDP, na.rm = TRUE),3), round(max(data$Freedom, na.rm = TRUE),3), round(max(data$Avg_sunshine, na.rm = TRUE),3), round(max(data$Avg_sunshine, na.rm = TRUE),3), round(max(data$Avg_sunshine, na.rm = TRUE),3)),

 #min
 min = c("", round(min(data$Year, na.rm = TRUE),3), round(min(data$Happiness, na.rm = TRUE),3), round(min(data$Log_GDP, na.rm = TRUE),3), round(min(data$Freedom, na.rm = TRUE),3), round(min(data$Avg_sunshine, na.rm = TRUE),3), round(min(data$Avg_sunshine, na.rm = TRUE),3), round(min(data$Avg_sunshine, na.rm = TRUE),3)))

summary_var

```



```{r, results = 'show'}
#display variable summary table
summary_var %>%
  setNames(c("Variable Names", "Type", "Q1", "Median", "Q3", "Mean", "Maximum", "Minimum")) %>%
  knitr::kable(caption = "Table 4: Summary Statistics for Variables in Merged Data Set") %>%
  kable_styling(latex_options = "HOLD_position")

```

I checked the distributions of each variable by plotting the respective histograms. I recognized that freedom is left-skewed, which means that the data is a better representation for countries with more freedom. Happiness score is normally distributed, which a good indication that one of the assumptions for linear regression is satisfied. As for average sunshine hours, it holds a bimodal distribution with the two peaks at around 1800 and 3000 hours. There are two explanations for this: countries with 1800 and 3000 yearly sunshine duration participate in the happiness report for a lot of the years, or there are more countries with 1800 and 3000 yearly sunshine hours. 


```{r, out.width="70%", out.height="70%", fig.align='center', fig.cap = "Distribution of interest variables, Log GDP, Sunshine Hours, Freedom, and Happiness"}
#distribution of variables
par(mfrow = c(2, 2))
hist(data$Log_GDP, xlab = 'Log GDP per Capita', main = 'Distribution of Log GDP per Capita')  
hist(data$Avg_sunshine, xlab = 'Average Yearly Sunshine (hrs)', main = 'Distribution of Average Yearly Sunshine')  
hist(data$Freedom, xlab = 'Freedom Score', main = 'Distribution of Freedom Score')  
hist(data$Happiness, xlab = 'Happiness Score', main = 'Distribution of Happiness Score')  

```

I also used the pairs plot function in R to explore the relationship between each of the variables and detect for possible linear relationships. As a result, I recognized that there are potential linear relationships between the variables Happiness and log GDP in particular.

```{r, out.width="50%", out.height="50%", fig.align='center', fig.cap = "This is a pairs plot for variables of interest."}

panel.points<-function(x,y)
{
  points(x,y,cex=0.2)
}


pairs(data[,3:6],upper.panel=panel.points, main = "Pairs Plot: Happiness, Log GDP, Freedom, and Average Sunshine Hours", cex.main = 1)
```


```{r}
# create table of number of countries reported for each year
country_records <- data %>% group_by(Country) %>% mutate(record_count = n())
Year_records <- data %>% group_by(Year) %>% summarise(count = n())
t <- t(Year_records)
rownames(t) <- c("Year", "Countries Reported")
```

In addition, I realized that not every country was recorded the same number of times in the data set. This may cause a biased resultof the mean GDP or happiness score for each year, and this is something to keep in mind, which I will address later. 

```{r, results = 'show'}
#display table of number of countries reported for each year
t %>% 
  setNames(c("Year", "Countries Reported")) %>%
  knitr::kable(caption = "Number of Countries Participated in Happiness Report Each Year") %>% 
  kable_styling(latex_options=c("scale_down","HOLD_position"))
```

\newpage 

# Results

The results section is divided into 6 sections and each of them uses various techniques to answer different components of the research question. As a prelude, I will briefly introduce each of the sections. Section 1 looks at how mean happiness score changes overtime; section 2 focus on the distribution of GDP, freedom scores, and sunshine hours based on groupings determined by happiness score; section 3 shows the distribution of happiness score based on sunshine, freedom, and income levels; section 4 utilizes a linear model using happiness as a response variable; section 5 does cubic spline modeling based on a small modification on time; section 6 utilizes more complex modeling, including bagging, random forest, boosting, and XG boosting. 


## 1. Mean Happiness Score Overtime

```{r}
# yearly statistics of gdp, happiness, freedom (didn't put in final report)
sum0<- data %>% group_by(Year) %>% summarise(mean_GDP = mean(Log_GDP, na.rm = TRUE),
                                               max_GDP = max(Log_GDP, na.rm = TRUE), 
                                               min_GDP = min(Log_GDP, na.rm = TRUE), 
                                            mean_Happiness = mean(Happiness, na.rm = TRUE),
                                               max_Happiness = max(Happiness, na.rm = TRUE), 
                                               min_Happiness = min(Happiness, na.rm = TRUE), 
                                              mean_freedom = mean(Freedom, na.rm = TRUE), 
                                               max_freedom = max(Freedom, na.rm = TRUE), 
                                               min_freedom = min(Freedom, na.rm = TRUE), 
                                               countries = n_distinct(Country, na.rm = TRUE),
                                                n = n(),
                                              )
sum0
```




```{r}

#records after 2010
country_records2 <- data %>%  filter(Year >= 2010) %>% group_by(Country) %>% mutate(record_count = n())

#maximum amount of time country was reported
max_count <- max(country_records2$record_count)

#filter out countries that don't appear for "max count of times"  after 2010
freq_countries <- country_records2 %>% filter(record_count >= max_count) 


#yearly mean happiness in selected countries
main_plt_data <- freq_countries %>% group_by(Year) %>%summarise(mean_happiness = mean(Happiness), level = "Overall", n=n())


#mean of gdp, sunshine, and freedom
mean_gdp = mean(freq_countries$Log_GDP)
mean_sunshine = mean(freq_countries$Avg_sunshine)
mean_freedom = mean(freq_countries$Freedom)

#create income category 
levels_countries_income <- freq_countries %>% mutate(level = case_when(Log_GDP >= mean_gdp 
                                                   ~ "Income Above Average", TRUE ~"Income Below Average" )) 

#calculate the mean happiness in each year by income category
plt_income <- levels_countries_income %>% group_by(Year, level) %>% summarise(mean_happiness = mean(Happiness), n=n())



#create sunshine category 
levels_countries_sunshine <- freq_countries %>% mutate(level = case_when(Avg_sunshine >= mean_sunshine 
                                                   ~ "Sunshine Above Average", TRUE ~"Sunshine Below Average" )) 



#calculate the mean happiness score in each year by sunshine category
plt_sunshine <- levels_countries_sunshine %>% group_by(Year, level) %>% summarise(mean_happiness = mean(Happiness), n=n())


plt_sunshine
# create freedom category
levels_countries_freedom <- freq_countries %>% mutate(level = case_when(Freedom >= mean_freedom 
                                                   ~ "Freedom Above Average", TRUE ~"Freedom Below Average" )) 

#calculate the mean happiness score in each year by freedom category
plt_freedom <- levels_countries_freedom %>% group_by(Year, level) %>% summarise(mean_happiness = mean(Happiness), n=n())


#combine the data frames
time_plot <- bind_rows(plt_income, plt_sunshine, plt_freedom, main_plt_data)

```


```{r, fig.show='hide'}
#plot time series plot
 p2 <- ggplot(data=time_plot, aes(x=Year,y = mean_happiness, color = level)) +
geom_line() + 
  geom_point(data=time_plot, aes(x=Year,y = mean_happiness)) + guides(fill=guide_legend(title="Country Category")) + 
   labs(y = "Mean Happiness Score", x = "Year", title = "Mean Happiness Score Overtime for Countries recorded every year bewteen 2010-2020") + theme(plot.title = element_text(size=10))

#adjust x-axis scales
 p2+ 
scale_x_continuous(breaks= c(2010, 2015, 2020))
```
Please refer to interactive visualizations [Figure 2](https://jennylin331431.github.io/jsc370-website/final_project_visuals.html#Figure_2) on the website for this component. 


**Explanation:**

As mentioned previously, not every country is recorded every year between 2005 to 2020. Therefore, if we analyze the mean happiness score progression over time using all observations, there would be inaccurate results. For instance, the mean happiness score may increase because a country with high happiness score was added in the later years. Therefore, I chose to only report the mean happiness score for countries that participated in the Happiness report every year between 2010 to 2020. Furthermore, I separated the trend for mean happiness score into categories based on income levels (above or below average), freedom levels (above or below average), and sunshine hours (above or below average). An overall trend in mean happiness score for these countries without categorizing is also displayed. 

As a result, we can inspect that there is no specific trend in the happiness score overtime.The overall trend is rather horizontal with small ups and downs; there is not much change over time. Also, for some categories, happiness score increases, while it decreases in other categories. For instance, countries with freedom scores above average, the mean happiness score decreases, while in the countries of sunshine hours below average, the happiness score decreases. Moreover, an interesting observation I found is that between 2011 - 2014, the mean happiness score in most categories decreases; however, for the category of freedom level above average, the mean score significantly increases.

Although these are simply trends observed in the countries that were reported every year, it is still a good indication of how happiness has progressed overtime. In fact, we can still gain brief insights regarding the effects of income, freedom, and sunshine overtime. As we can see, countries with income below the average have the lowest mean happiness score in every year, followed by countries with income below the average and sunshine duration above average. Meanwhile, countries with income above the average have the highest mean happiness score overtime, followed by freedom above averaged countries. This allows us to suggest that high income and freedom give rise to the happiness score.



## 2. Distribution of GDP, Freedom Score, and Sunshine Hours by Happiness Score 


```{r}
#calculate mean score for each year
data2 <- data %>% group_by(Year) %>% mutate(mean_happiness_score = mean(Happiness, na.rm = TRUE))

# count number of times happiness score is above average for each country
data2 <- data2 %>% group_by(Country) %>% mutate(count_above_average = sum(Happiness >= mean_happiness_score),
                                              country_appear = n())

# create category of frequency of happiness score above average for each country
data2 <- data2 %>% mutate(above_average = case_when(count_above_average/country_appear >= 2/3 
                                                   ~ "at least 2/3", 
                                                   count_above_average/country_appear < 1/3 ~ "less than 1/3",
                                                TRUE ~ "1/3 to 2/3"))

```

```{r}
#create table that groups by the frequency of happiness score above average for each country
pre2<- data2 %>% group_by(above_average) %>% summarise(mean_GDP = mean(Log_GDP, na.rm = TRUE),
                                               max_GDP = max(Log_GDP, na.rm = TRUE), 
                                               min_GDP = min(Log_GDP, na.rm = TRUE), 
                                               mean_sunshine = mean(Avg_sunshine, na.rm = TRUE),
                                               max_sunshine = max(Avg_sunshine, na.rm = TRUE), 
                                               min_sunshine = min(Avg_sunshine, na.rm = TRUE),
                                              mean_freedom = mean(Freedom, na.rm = TRUE), 
                                               max_freedom = max(Freedom, na.rm = TRUE), 
                                               min_freedom = min(Freedom, na.rm = TRUE), 
                                               countries = n_distinct(Country, na.rm = TRUE)
                                               )
```

```{r, results = 'show'}
#display table that groups by the frequency of happiness score above average for each country
pre2[,c(1, 2, 3, 4, 11)] %>% 
  setNames(c("Happiness Frequency", "Average Log GDP", "Max Log GDP", "Min Log GDP", "# of Countries")) %>%
  knitr::kable( caption = "Summary of GDP based on Happiness Frequency Grouping")%>% 
  kable_styling(latex_options=c("HOLD_position"))
```

```{r, results = 'show'}
#display table that groups by the frequency of happiness score above average for each country
pre2[,c(1, 5, 6, 7)] %>% 
  setNames(c("Happiness Frequency", "Average Sunshine Hours", "Max Sunshine Hours", "Min Sunshine Hours")) %>%
  knitr::kable( caption = "Summary of Sunshine Hours based on Happiness Frequency Grouping")%>% 
  kable_styling(latex_options=c("HOLD_position"))
```

```{r, results = 'show'}
#display table that groups by the frequency of happiness score above average for each country
pre2[,c(1, 8, 9, 10)] %>% 
  setNames(c("Happiness Frequency", "Average Freedom Score", "Max Freedom Score", "Min Freedom Score")) %>%
  knitr::kable( caption = "Summary of Freedom Score based on Happiness Frequency Grouping")%>% 
  kable_styling(latex_options=c("HOLD_position"))
```
**Explanation:**

This is a summary table done by categorizing countries by their levels of happiness. I define three categories for the countries based on the frequency of their happiness scores being greater or equal to the mean happiness score of the corresponding year. There are three groups in total: less than $\frac{1}{3}$, $\frac{1}{3}$ to $\frac{2}{3}$ , and at least $\frac{2}{3}$. The categories can be interpreted as follows: if a country appears in the less than $\frac{1}{3}$ category, this means that out of all the years the country participated in the World Happiness Report, less than $\frac{1}{3}$ of their records yielded a happiness scores higher or equal to the mean happiness of that same year. 

As a result of the summary table, the category of "at least $\frac{2}{3}$" yields the highest average log GDP and average freedom score, whereas the highest average sunshine appears in the "less than $\frac{1}{3}$" category. Also, the maximum log GDP occurs in countries with at least $\frac{2}{3}$ being happy and the minimum occurs in the "less than $\frac{1}{3}$" category. This suggests that countries with higher GDP have higher happiness. A similar result applies on the factor freedom, which suggests that countries with higher freedom lead to more happiness. On the contrary, the category of "less than $\frac{1}{3}$" yields the maximum sunshine hours, while the minimum occurs in the "at least $\frac{2}{3}$" category. This allows us to say that sunshine hours doesn't increase happiness, but perhaps decreases. 

Here, however, we can see there is an uneven distribution of categories. The $\frac{1}{3}$ to $\frac{2}{3}$ category only has 11 countries, whereas the other two groups have over 50. We may need to consider potential bias in further analysis using this table due to the under population of the  $\frac{1}{3}$ to $\frac{2}{3}$ category. 

As a note, I used the maximum of maximum yearly sunshine and minimum of minimum yearly sunshine to record the maximum and minimum sunshine hours for each category, rather than the maximum and minimum values of average yearly sunshine. 



## 3. Distribution of Happiness Score by Sunshine, Freedom, and Income Levels


```{r}
#create income level
data3 <- data %>% mutate(income_level = case_when((Log_GDP <= 
                                                   quantile(Log_GDP, probs =0.25, na.rm = TRUE)) ~ "Low",
                                                 (quantile(Log_GDP, probs =0.25, na.rm = TRUE) < Log_GDP & Log_GDP<= 
                                                   quantile(Log_GDP, probs =0.75, na.rm = TRUE)) ~ "Medium",
                                                TRUE ~ "High"))


#create sunshine level
data3 <- data3 %>% mutate(sunshine_level = case_when((Avg_sunshine < 
                                                   quantile(data$Avg_sunshine, probs =0.5, na.rm = TRUE)) ~ "Low Sunshine Level",TRUE ~ "High Sunshine Level"))


#create freedom level
data3 <- data3 %>% mutate(freedom_level = case_when((Freedom < 
                                                   quantile(data$Freedom, probs =0.5, na.rm = TRUE)) ~ "Low Freedom Level",TRUE ~ "High Freedom Level"))

```
```{r, fig.cap="Distribution of happiness score based on sunshine Level, freedom level, and income Level (individually)", out.width="80%", out.height="80%", fig.align='center'}

#reorder x-axis
data3$income_level <- factor(data3$income_level , levels=c("High", "Medium", "Low"))
data3$sunshine_level <- factor(data3$sunshine_level , levels=c("High Sunshine Level", "Low Sunshine Level"))

data3$freedom_level <- factor(data3$freedom_level , levels=c("High Freedom Level", "Low Freedom Level"))

#income level plt    
l1 <- ggplot(data = data3, mapping = aes(x = income_level, y = Happiness)) + 
geom_boxplot(fill="pink")+ labs(x = "Income Level", y= "Happiness Score") 



#sunshine_level plt                                              
l2 <- ggplot(data = data3, mapping = aes(x = sunshine_level, y = Happiness)) + 
geom_boxplot(fill="mediumpurple1") + labs(x = "Sunshine Level", y= "Happiness Score") + scale_x_discrete(labels=c("High Sunshine Level" = "High", "Low Sunshine Level" = "Low"))


#freedom level plt                                              
l3 <- ggplot(data = data3, mapping = aes(x = freedom_level, y = Happiness)) + 
geom_boxplot(fill="lavenderblush1") + labs(x = "Freedom Level", y= "Happiness Score") + scale_x_discrete(labels=c("High Freedom Level" = "High", "Low Freedom Level" = "Low"))


#combine the three plots
ggarrange(l1, l2, l3, 
          ncol = 2, nrow = 2) + labs(title = "Distribution of Happiness Score based on Sunshine Level, Freedom Level, and Income Level")+ theme(plot.title = element_text(size=10)) 
```


```{r, fig.cap="Distribution of happiness score with various combinations based on sunshine Level, freedom Level, and income Level"}
#create boxplot of happiness score that groups by sunshine, freedom, and income level
level_plt <- ggplot(data = data3, mapping = aes(fill = income_level, y = Happiness)) + 
geom_boxplot() + facet_wrap(~sunshine_level + freedom_level) + labs(x = "Income Level", y= "Happiness Score", title = "Distribution of Happiness Score based on Sunshine Level, Freedom Level, and Income Level (Combined)") + theme(plot.title = element_text(size=10), axis.text.x=element_blank()) + scale_fill_manual(values=c("purple",
                               "hotpink1", "yellow"
                               )) + guides(fill=guide_legend(title="Income Level"))


level_plt
```

**Note**: For interactive visualizations of Figure 1 and 2, please refer to interactive visualizations [Figure 3](https://jennylin331431.github.io/jsc370-website/final_project_visuals.html#Figure_3) on the website. 


**Explanation:**

Income is separated into three levels: high, medium, and low. A "low" income indicates the log GDP per capita is less than or equal to the first quantile of log GDP per capita, whereas "medium" indicates that it lies between the first and third quantile, and "high" when it is above the third quantile. Freedom score and sunshine hours are classified into two groups by comparing with the mean values: high and low. 

By inspecting interactive visualizations figure 3, a high income level generally generates a higher average happiness score, and similarly for high freedom levels. As for sunshine levels, low sunshine levels typically yield a higher happiness score. The low freedom level group possesses a smaller interquartile range than that of the high freedom level group, meaning that its happiness scores has the least variations. Meanwhile, the variation between the high, medium, and low income group and the variation between the high and low sunshine level group is rather similiar. Moreover, there a few outliers with low happiness score in the high, medium, and low income, which suggests that there are still countries in each of these groups that possess a lower happiness score than the average.


Through figure 4, we can also infer about the greatness of effects between whether the decrease in happiness that sunshine causes is larger than that of the increase income and freedom causes. We can suggest that perhaps income has a larger effect than sunshine on happiness. This is because the group of low sunshine, low income yields a lower mean happiness score than the group with high sunshine and high income, holding freedom level fixed. As for comparing the effects of freedom level and sunshine level, the result is uncertain. We can see that the group of high income, high sunshine, high freedom yields a higher mean happiness score than the group of high income, low sunshine, low freedom. However, when income is medium leveled, the results do not hold; the high sunshine, high freedom yields a lower mean happiness than that of low sunshine, low freedom group. Obviously, these results may still be biased if some subgroups are under populated. 


## 4. Linear Model 

```{r, fig.show='hide'}
#generate scatter plot of happiness vs. sunshine 
g1<- ggplot(data = data, mapping = aes(x = Avg_sunshine, y = Happiness)) + 
  geom_point(size = 1) + 
 geom_smooth(method='lm', formula= y ~ x) + labs(x = "Average Sunshine Hours", y = "Happiness Score", title = "Happiness Score vs. Average Sunshine Hours")+ theme(plot.title = element_text(size=10))

#generate scatter plot of happiness vs. Freedom 
g2<-ggplot(data = data, mapping = aes(x = Freedom, y = Happiness)) + 
  geom_point(size = 1) + 
 geom_smooth(method='lm', formula= y ~ x) + labs(x = "Freedom Score", y = "Happiness Score", title = "Happiness Score vs. Freedom Score")+ theme(plot.title = element_text(size=10))

#generate scatter plot of happiness vs. Log_GDP 
g3 <- ggplot(data = data, mapping = aes(x = Log_GDP, y = Happiness)) + 
  geom_point(size = 1) + 
 geom_smooth(method='lm', formula= y ~ x) + labs(x = "Freedom Score", y = "Log GDP Per Capita", title = "Happiness Score vs. Log GDP Per Capita")+ theme(plot.title = element_text(size=10))

#combine plot
ggarrange(g1, g2, g3, ncol = 2, nrow = 2) 
```



```{r}
#fit linear model 
model <- lm(data = data, Happiness ~ Log_GDP + Freedom + Avg_sunshine)

#model sumamry
summary(model)
```

```{r, results = 'show'}

#create table of model summary
coef_summary <- data.frame(terms = c("Intercept", "Log GDP per capita", "Freedom Score", "Average Sunshine"), coeff_estimate = c(-2.112, 0.6432, 2.409, -0.0000886), significance = c("Yes", "Yes", "Yes", "Yes"))


#display table of linear model summary
coef_summary %>%
  setNames(c("Terms", "Coefficient Estimate", "Significance"))  %>%
  knitr::kable(caption =  "Linear Model Coefficients with Significance") %>% 
  kable_styling(latex_options=c("HOLD_position"))
```

```{r}
#remove Average sunshine variable from model
model2 <- lm(data = data, Happiness ~ Log_GDP + Freedom)
summary(model2)
```

Please also refer to interactive visualizations [Figure 4](https://jennylin331431.github.io/jsc370-website/final_project_visuals.html#Figure_4) on the website for this component. 


**Explanation:**


In this part, I performed an analysis between happiness scores and the following predictors, freedom score, average sunshine hours, and log GDP per capita. In [Figure 4](https://jennylin331431.github.io/jsc370-website/final_project_visuals.html#Figure_4), we can see that as freedom score and log GDP Per Capita increases, the happiness score increases. There is a positive association. On the other hand, there is a negative association between happiness score and average sunshine hours; as sunshine hours increase, the happiness score decreases. 

Trends in the plot is also reflected in the linear model after fitting. All the predictors are deemed to be significant, which means we can interpret their impacts on happiness score using the coefficients produced. For the terms, freedom score and log GDP per capita, the coefficients are positive; as freedom score and log GDP per capita increases, happiness increases as well. As a note, a small change in freedom score causes a larger increase in happiness score than that of log GDP per capita, which I suppose is due to the small range of freedom score, 0 to 1. On the other hand, sunshine hours lower the happiness score, but the coefficient is so small that there is nearly no effect. 

An adjusted R-squared of 0.7102 has also been reported. This means that 70% of the variability in happiness is being explained by our model, which means that our model is not a poor fit. After attempting to remove the predictor, Average sunshine, the adjusted R-squared only decreases by 0.0016, which is extremely low, and this suggests that sunshine hours does not directly impact happiness. 

Previously, when I used the average sunshine hours over cities to represent a country's sunshine hours, sunshine hours were deemed to be insignificant and the coefficients for other terms remain extremely similar.  


## 5. Cubic Spline Model 

```{r, out.width="60%", out.height="60%", fig.align='center', fig.cap = "Cubic spline model fit on variable, year"}
# fit a model by cubic spline
gmod <- gam(Happiness~s(Year,k = 10, fx = FALSE, bs = "cr") + Log_GDP + Freedom + Avg_sunshine, data = data)
plot(gmod, main = "Cubic Spline Fit on Year")

summary(gmod)
```
```{r, results = 'show'}
#create table of model summary
coef_summary2 <- data.frame(terms = c("Intercept", "Log GDP per capita", "Freedom Score", "Average Sunshine"), coeff_estimate = c(-2.2469, 0.6577, 2.576, -0.00004676), significance = c("Yes", "Yes", "Yes", "No"))


#display table of linear model summary
coef_summary2 %>%
  setNames(c("Terms", "Coefficient Estimate", "Significance"))  %>%
  kable(caption =  "Cubic Spline (on Year) Model Summary")%>% 
  kable_styling(latex_options=c("HOLD_position"))
```

**Explanation:**

I fit a cubic spline regression model having 10 knots on the variable, Year, along with other variables including economic status, freedom, and sunshine hours. From figure 3, we can see that there is a slight increase in happiness in between years 2005 -2008, and from 2008 onward, the happiness decreases. Until 2017, the happiness slightly rises again. Also, it is worthy to note that the trend between 2010-2020 shares a few similarities from the plot in part 1, such as the slight increase from 2017 - 2020 and the decrease from 2013 - 2015. 

However, the adjusted R-squared for this model is 0.72, which isn't a very large difference from the linear model fitted in part 4. This means that happiness is not explained by time as much. In fact, the coefficients of the other variables remain extremely similar as well. Therefore, through this model, we can say that time doesn't play a big role in affecting happiness.



## 6. More Complex Modelling 

I performed a $70/30$ train test split on the data set, and built the models using the four variables of interest, `Log_GDP`, `Avg_sunshine`, `Year`, and `Freedom`, based on a selection of hyperparameters as specified below. The models include bagging, random forest, boosting, and XG boosting.

```{r}
set.seed(0) # set seed for generating random data.

# createDataPartition() function from the caret package to split the original dataset into a training and testing set and split data into training (80%) and testing set (20%)
parts = createDataPartition(data$Happiness, p = .7, list = F)
train = data[parts, ]
test = data[-parts, ]

# #define predictor and response variables in training set
train_x = data.matrix(train[, c(2, 4, 5, 6)])
train_y = train[,3]

#define predictor and response variables in testing set
test_x = data.matrix(test[, c(2, 4, 5, 6)])
test_y = test[,3]

#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)

```


```{r}
p <- 3
# performance metrics on the test data
cal_stats <- function(pred_y){
  mse <- mean((test_y - pred_y)^2) #mse - Mean Squared Error
  n <- length(pred_y)

rmse <- caret::RMSE(test_y, pred_y) #rmse - Root Mean Squared Error

y_test_mean = mean(test_y)
# Calculate total sum of squares
tss =  sum((test_y - y_test_mean)^2 )
# Calculate residual sum of squares
rss =  sum((test_y - pred_y)^2)
# Calculate R-squared
rsq  =  1 - (rss/tss)
# adj_rsq = 1 - (1 - rsq)*(n-1)/(n-p - 1)
cat("mse: ", mse, '\n')
cat("rmse: ", rmse, '\n')
cat('R-squared', round(rsq,3), '\n')

# x = 1:length(test_y)                   # visualize the model, actual and predicted data
# plot(x, test_y, col = "red", type = "l")
# lines(x, pred_y, col = "blue", type = "l")
# legend(x = 1, y = 38,  legend = c("original test_y", "predicted test_y"), 
#        col = c("red", "blue"), box.lty = 1, cex = 0.8, lty = c(1, 1))

return (c(mse, round(rsq,3)))
}

```


**Bagging:** 

No specific hyperparameters were specified for Bagging, as this model seeks out different value combinations already.

```{r, warning = FALSE}
set.seed(200)
#bagging model
n_features <- 3
bagging_model <- randomForest(Happiness ~ Log_GDP + Freedom + Avg_sunshine + Year , 
                              data = train, 
                              mtry = n_features, 
                              na.action = na.omit)



```
```{r}
pred_y = predict(bagging_model, test[, c(2, 4, 5, 6)])
result_bagging <-cal_stats(pred_y)
```

**Random Forest:**

No specific hyperparameters were specified for Random Forest, as this model seeks out different value combinations already.


```{r, warning = FALSE}
set.seed(200)
#random forest model
n_features <- 3
random_forest_model <- randomForest(Happiness ~ Log_GDP + Freedom + Avg_sunshine + Year , 
                              data = train, 
                              # mtry = n_features, 
                              na.action = na.omit)



```


```{r}
pred_y = predict(random_forest_model, test[, c(2, 4, 5, 6)])
result_random_forest <- cal_stats(pred_y)
```


**Boosting:**


I set the number of trees to be 1000 and learning rate at 0.3. I tested different learning rates between 0.01 and 0.3 and recognized that 0.3 yields the smallest MSE out of these values. 


```{r}
set.seed(200)
#shrinkage values 
shrinkages <- seq(0.01, 0.3, by = 0.01)

#helper to construct boosting model by shrinkages
boost_model <- function(shrinkage){
   gbm(Happiness ~ Log_GDP + Freedom + Avg_sunshine + Year , 
                    data = train, 
                   shrinkage = shrinkage,
                   distribution = "gaussian",
                   n.trees = 1000
                 )
}

#helper to calculate mse
cal_mse <- function(data, model){
  prediction <- predict(model, data, verbose = FALSE)
  1/nrow(data) * sum((prediction- data$Happiness)**2)
}


```


```{r, message = FALSE, , fig.show='hide'}
#calculate mse for each shrinkage
mse <- c()
for(i in shrinkages){
  model <- boost_model(i)
  mse <- c(mse, cal_mse(train, model))
}


#plot mse vs. shrinkage
ggplot() + geom_point(aes(x = shrinkages ,y= mse)) + labs(title = "MSE vs. Shrinkage on Boosting", x = "Shrinkage", y = "MSE")
```


```{r}
boost_final_model <-boost_model(0.3)
#variable importance plot
sum_boost <- summary.gbm(boost_final_model,   plotit = FALSE)


```
```{r}
pred_y = predict.gbm(boost_final_model, test[, c(2, 4, 5, 6)])
result_boosting <- cal_stats(pred_y)
```




**XG Boosting:**

To select the hyperparameters, I modeled a max depth of 3, 5, 7, 9. For each of these depths, I first ran an epoch of 1000 rounds at a learning rate of 0.2, and to select the final number of epochs, I chose the iteration where MSE stops decreasing. This is because when the MSE starts to increase slightly, this indicates over fitting of the data. After, I compared the mse and adjusted R-squared of these 4 models, and chose to use the model with a max depth of 9, nrounds of 53, and learning rate of 0.2. 



```{r}
#defining a watchlist
watchlist = list(train=xgb_train, test=xgb_test)


## code that was used to tune "nrounds" for each max depth
# #fit XGBoost model and display training and testing data at each iteartion
# model1 = xgb.train(data = xgb_train, max.depth = 3, watchlist=watchlist, nrounds = 1000, eta = 0.2)
# model2 = xgb.train(data = xgb_train, max.depth = 5, watchlist=watchlist, nrounds = 1000, eta = 0.2)
# model3 = xgb.train(data = xgb_train, max.depth = 7, watchlist=watchlist, nrounds = 1000, eta = 0.2)
# model4 = xgb.train(data = xgb_train, max.depth = 9, watchlist=watchlist, nrounds = 1000, eta = 0.2)


```


```{r}
#define final model
model_xgboost1 = xgboost(data = xgb_train, max.depth = 3, nrounds = 443, verbose = 0, eta = 0.2)
#define final model
model_xgboost2 = xgboost(data = xgb_train, max.depth = 5, nrounds = 201, verbose = 0, eta = 0.2)
#define final model
model_xgboost3 = xgboost(data = xgb_train, max.depth = 7, nrounds = 240, verbose = 0, eta = 0.2)
model_xgboost4 = xgboost(data = xgb_train, max.depth = 9, nrounds = 53, verbose = 0, eta = 0.2)
```


```{r}
#use model to make predictions on test data
pred_y1 = predict(model_xgboost1, xgb_test)
pred_y2 = predict(model_xgboost2, xgb_test)
pred_y3 = predict(model_xgboost3, xgb_test)
pred_y4 = predict(model_xgboost4, xgb_test)
```


```{r}
#test hyperparameters
cal_stats(pred_y1)
cal_stats(pred_y2)
cal_stats(pred_y3)
result_xgboost <- cal_stats(pred_y4)
```


```{r, out.width="70%", out.height="70%", fig.align='center', fig.cap="Variable importance plot for models, Bagging and Random Forest"}
#get variable importance
bagging_importance <- varImp(bagging_model)
forest_importance <- varImp(random_forest_model)

bagging_importance$variables <- rownames(bagging_importance)[order(bagging_importance$Overall, decreasing=TRUE)]
forest_importance$variables <- rownames(forest_importance)[order(forest_importance$Overall, decreasing=TRUE)]

#variance importance plot - bagging 
bagging_var <- ggplot(bagging_importance, aes(x=reorder(variables, Overall), y=Overall)) + 
      geom_bar(stat="identity", position="dodge", fill = "pink") +
      coord_flip() + labs(title = "Variable Importance plot (Bagging)", y = "Importance", x = "Variable")+ 
  theme_minimal() + 
  theme(axis.text=element_text(size=10),axis.title = element_text(size=11))


#variable importance plot - random forest
forest_var <- ggplot(forest_importance, aes(x=reorder(variables, Overall), y=Overall)) + 
      geom_bar(stat="identity", position="dodge", fill = "pink") +
      coord_flip() + labs(title = "Variable Importance Plot (Random Forest)", y = "Importance", x = "Variable")+ 
  theme_minimal() + 
  theme(axis.text=element_text(size=10),axis.title = element_text(size=11))

ggarrange(bagging_var, forest_var, nrow = 2,ncol = 1)
```

```{r}
#variable importance plot
boost_var <- ggplot(sum_boost, aes(x=reorder(var, rel.inf), y=rel.inf)) + 
      geom_bar(stat="identity", position="dodge", fill = "pink") +
      # scale_x_discrete(limits = as.character(11:8)) +
      coord_flip() + labs(title = "Variable Importance Plot (Boosting)", y = "Importance", x = "Variable") +  
  theme_minimal() + 
  theme(axis.text=element_text(size=10),axis.title = element_text(size=11))


# Compute feature importance matrix
importance_matrix = xgb.importance(colnames(xgb_train), model = model_xgboost4)
importance_matrix
# print(xgb.plot.importance(importance_matrix = importance_matrix))


#variance importance plot
xg_boost_var <- ggplot(importance_matrix, aes(x=reorder(Feature, Gain), y=Gain)) + 
      geom_bar(stat="identity", position="dodge", fill = "pink") +
      # scale_x_discrete(limits = as.character(11:8)) +
      coord_flip() + labs(title = "Variable Importance Plot (XG Boost)" ,x = "Variables", y = "Importance" ) + 
  theme_minimal() + 
  theme(axis.text=element_text(size=10),axis.title = element_text(size=11))
```
```{r, out.width="70%", out.height="70%", fig.align='center', fig.cap="Variable Importance Plot for models, Xg Boosting and Boosting"}
ggarrange(boost_var, xg_boost_var,  ncol = 1, nrow = 2)
```


**Test Accuracy:**


To obtain the accuracy of our models, I fitted the model on the test set and computed computed the Mean Squared Error and the R-squared produced by the four models. I did not compute the adjusted R-squared for these models because after some careful research, I recognized that adjusted R-squared is not a suitable metric for nonlinear models.    



```{r}
test_result <- data.frame(method = c("Bagging", "Random Forest", "Boosting", "XG Boosting"), mse = c(result_bagging[1], result_boosting[1], result_random_forest[1], result_xgboost[1]), rsq = c(result_bagging[2], result_boosting[2], result_random_forest[2], result_xgboost[2]))
```


```{r, results = 'show'}
#display raw sunshine data
test_result %>% 
  knitr::kable(caption = "Modelling Test Accuracy Scores",  
               col.names = c("Method",
                           "MSE", "R-squared"
                           )) %>% 
  kable_styling(latex_options=c("HOLD_position"))
```

**Interpretations:**

From all the models, the variable of importance is in the following order: `Log_GDP`, `Freedom`, `Avg_sunshine`, and `Year`. Out of these factors, the most important factor for a model to make accurate prediction is GDP. The models rely on it alot to make predictions. This could be an indication that it influences our response variable the most. A citizen's income can highly determine their happinesss, followed by freedom, sunshine hours received, and time period. 

We can see that the XG Boosting model yields the lowest MSE, while it gives the highest R-squared. This suggests that it is the best model out of the four models. In fact, all of these models perform better than that of the linear model and spline basis fitted in part 5, as they are more complex. This is not surprising since XG Boosting is a higher level implementation of gradient boosting that uses advanced regularization (L1 & L2), and this highly improves its model generalization abilities. With an R-squared of 0.868, approximately 86% of the variability in the Happiness score is explained by the predictors within the XG boosting model. On the other hand, Random Forest yields the highest MSE and lowest R-squared, my best guess for this result is that random forest only chooses a subset of predictors on a split. Therefore, with only 4 predictors in our case, it might be lose accuracy when even less predictors are being used. 


\newpage 

# Conclusion 

In this report, our primary questions are to see whether happiness increase over time and whether a citizen's happiness is impacted by their economic status, freedom, and sunshine hours received. 

Based on the results of 1 and 5, we can see that there is no particular trend in the increase of happiness overtime, and it is rather similar over the years. However, there is a particular drop between 2011 - 2014 in the mean happiness score, which is worth noting. As of the factors that influence happiness, both economic status and freedom increase happiness. On the other hand, sunshine hours decreases happiness score; however, its decrease in happiness score is so minimal that it can be neglected. In terms of how much these factors impact happiness, economic status, followed by freedom, are what causes a more significance influence, compared to that of sunshine hours and time period. 

Therefore, the main takeaway from this analysis is that higher economic status and more freedom given lead to happier individuals. 


# Limitations

One major limitation of this study is that the sunshine data set only contains the sunshine hours for particular countries. An amount of countries were removed from the study despite their happiness score was recorded. If more observations and countries are included, the effects of factors that influence happiness can be considered from more parts of the world, adding variability to our data set in terms of country backgrounds. Another limitation is that sunshine hours differs widely across countries if the country is very large. Although I used population as an indicator for the representation within the country, it may not be the best deciding factor. Therefore, it may not be the most accurate amount of sunshine a citizen receives but simply a "best guess". It is more dependent on the city of the country they are in. Also, although sunshine hours do not differ as much across different years, there are still differences where some years may have slightly higher or less sunshine duration. Therefore, using the same amount of sunshine hours for every year in the data set may still cause some biased results that we need to be careful of. To add on, as mentioned previously, freedom score is right skewed; therefore, this analysis could not be as good for applying on countries with lower freedom, since our data set contains more observations with higher freedom scores. As a last limitation, the countries participating in the world happiness report every year is not the same, and this restricts how we analyze the happiness change over time and how we reference "yearly mean happiness score".   


